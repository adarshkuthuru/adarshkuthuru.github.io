<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Adarsh Kuthuru - Resources</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<header id="header">
					<a href="resources.html" class="logo">Resources</a>
				</header> 

				<a name ="top"></a> <!-- Tag for 'Back to Top' Button-->

				<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<!-- <li><a href="index_old.html">Test</a></li> -->
						<li><a href="index.html">About me</a></li>
						<li class="active"><a href="resources.html">Resources</a></li>
						<li><a href="projects.html">Projects</a></li>
					</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/adarshkp1/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/adarshkuthuru?tab=repositories" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">


						<!-- Post -->
							<section class="post">
								<!-- <header class="major"> -->
									<span class="date">April 16, 2022</span>
									<h2>Solving non-convex optimization problems</h2>
									<h3>Adarsh Kuthuru</h3>
									<!-- <h3>Explanation for why we can't use Neural Networks for non-convex optimization -->
										<!-- problems instead of Genetic Algorithms</h3> -->
								<!-- </header> -->
	
								<p>In order to choose any algorithm to solve a non-linear (non-convex) optimization problem, we need to consider the following factors:
									<ol>
									<li> How fast can the algorithm learn and converge? (Initialization matters a lot for this)</li>
									<li>  How to resolve if the solution gets stuck in local optima or saddle points?</li>
									<li>   Sensitivity of the algorithm to new data i.e., if the training data set is 
										not representative of the population, how would it perform with test data?</li>
									</ol> 
								

								<center>
								<figure>
								<div class="image"><img src="images/nonconvex.png" alt="" width="500" height="400"/></div>
								<figcaption><a href="https://medium.com/swlh/non-convex-optimization-in-deep-learning-26fa30a2b2b3">fig.</a> Surface of a non-convex objective function </figcaption>
								</figure>
								</center>
								

								<!-- for space -->
								&nbsp; 
								&nbsp; 
								
								<!-- <h3>1. How fast can the algorithm learn and converge?</h3> -->
								<h3>Challenges when using Neural networks for non-convex optimizations as opposed to genetic algorithms</h3>
								<ol>
								<li> <b>Hyperparamter Optimization: </b> <br> In comparison to Genetic Algorithms, Neural Networks have more hyperparameters to be optimized
									 like learning rate (need to be specified for gradient descent approach), 
								number of hidden layers required, number of neurons/nodes required in each layer, 
								choice of activation functions etc. in addition to factors like the number of iterations/epochs required. 
								It could take a significant/polynomial time to optimize all of the hyperparameters. Therefore, it is at least an NP-Hard problem.
								</li>

								<center>
									<figure>
									<div class="image"><img src="images/neuralnet.png" alt="" width="600" height="300"/></div>
									<figcaption><a href="https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/">fig.</a> Sample Neural Network with 3 hidden layers</figcaption>
									</figure>
								</center>

								
								&nbsp; 
								<li><b>Poor conditioning of the cost function: </b> <br> Genetic Algorithms do not require the error terms (cost function) to be minimized. 
									They follow a heuristic approach wherein the solutions are randomly generated 
									through techniques like selection, crossover, and mutation which are unique to them, and substituted in the objective functions to search for global optima. 
									Whereas if Neural Networks are used in an optimization problem, they are required to fit a model and minimize the residual term. 
									This means that there is a possibility of poor conditioning of the cost function.  
								</li>
								
								

								&nbsp; 
									Hessian matrices of cost functions, which are
									second-order partial derivatives of cost functions with respect to explanatory variables describe the local curvatures of the function along 
									the axes ot those variables.

									<center>
										<figure>
										<div class="image"><img src="images/hessian.png" alt="" width="250" height="200"/></div>
										<figcaption>fig. Hessian Matrix </figcaption>
										</figure>
									</center>


									Hence, hessian matrices are used to determine if a solution is a saddle point or not. But for neural networks, computing and storing full hessian matrix
									takes O(n<sup>2</sup>) memory, which is not feasible as they have complex cost functions. Hence, an approximation is 
									made using numerical methods like truncated-Newton algorithms, which lead to poor conditioning of errors. This could result in slower learning rates, rapid changes 
									in output for a small change in inputs etc., as the optimization process is not stable.
								</p>


								<li><b>Vanishing/Exploding Gradient problem:</b> <br> 
									In forward propagation, neural networks are initialized by assigning random weights to the nodes, transformed using an activation function, 
									and a non-linear model is fitted.
									In the process of backward propagation, the weights (slope) and the constant (intercept) are used to minimize the cost function as 
									per below formula and are updated at a pre-specified learning rate. This updation of weights approach is called gradient descent.<br> 

									&nbsp; 
									<center>
									<math>
										<b>W<sub>new</sub> = W<sub>old</sub> - α*<box>dL/dw</box> </b> <br> 
									

									<!-- Wnew = Wold – (α * dL/dw) -->

									where,

									W<sub>new</sub> = the new weight of explanatory variable X<sub>i</sub>; <br> 

									W<sub>old</sub> = the old weight of explanatory variable X<sub>i</sub>; <br> 

									α = learning rate; <br> 

									<box>dL/dw</box> is the partial derivative of the loss function for each of the Xs. 
										It is the rate of change of the loss function to the change in weight.

									</math>
									</center>

									<!-- <center>
										<figure>
										<div class="image"><img src="images/cost.jfif" alt="" width="200" height="50"/></div>
										<figcaption>fig. Gradient Descent formula </figcaption>
										</figure>
									</center> -->
								</li>

								&nbsp; 
								<p>
									Sometimes when this gradient approaches zero due to the characterstic of the activation functions or at saddle points and 
									local minima, the weights dont update. This is called vanishing gradient problem. When the gradient approaches infinity, 
									it is called exploding gradient problem. In sequential models like Recurrent Neural Networks, Long-short-term memory models (RNN/LSTM) 
									which are predominantly used for NLP, these mean 
									zero correlation of the current state with previous state and 100% correlation respectively.
								</p>

								<!-- &nbsp;  -->
								<center>
									<figure>
									<div class="animated-gif"><img src="images/Opt.gif" alt="" width="500" height="400"/></div>
									<figcaption><a href="https://pin.it/6E7hJn3">fig.</a> Learning and converging rates of some Neural network extensions that I will talk about below</figcaption>
									</figure>
								</center>
								<p>
									In order to address these various solutions were proposed like gradient clipping (where the gradients are constrained by a threshold), usage of 
									activation functions like Rectified Linear Units (ReLU), Stochastic Gradient Descent (SGD - adding a stochastic term to gradient descent which 
									updates weights randomly), Momentum, NAG, Adaptive Learning Rate, Adagrad, Adadelta, RmsProp etc.
								</p>
							
								<ul>
									<center>
										<figure>
										<div class="image"><img src="images/SGD.png" alt="" width="550" height="300"/></div>
										<figcaption><a href="https://ankit-ai.blogspot.com/2018/11/optimization-algorithms-for-machine.html">fig.</a> Stochastic Gradient Descent Vs Gradient Descent </figcaption>
										</figure>
									</center>

									<li><b>Stochastic Gradient Descent:</b> <br> 
										From the above animation and image, SGD is still at the risk of getting stuck in local minima. So we can eliminate it as a possible solution.
			
									</li>

									<li><b>Stochastic Gradient Descent with Momentum:</b> <br> 
										In the presence of curvature, regular SGD oscillates a lot as shown in the below image, thus delaying the process of converging. Therefore SGD with momentum approach was 
										propsoed wherein the gradient is averaged to dampen the oscillations and obtain a faster path to optimization.
									</li>
									<center>
										<figure>
										<div class="image"><img src="images/mom.png" alt="" width="450" height="150"/></div>
										<figcaption><a href="https://mitpress.mit.edu/books/deep-learning">fig.</a> (Left) Regular SGD, (right) SGD with Momentum. <br>Goodfellow, I., Bengio, Y. and Courville, A. (2016). Deep learning. MIT press.</figcaption>
										</figure>
									</center>
									
									<li><b>Adaptive learning rate:</b> <br> 
										In the below image, when we are trying to minimize the cost function 'J' which is a function of parameters <math>Θ<sub>1</sub> & Θ<sub>2</sub></math>,
										we need to optimize the magnitude of oscillations to be proportional to the range of the parameter. Hence, the learning rates should be lower for lower oscillations and vice versa.
									</li>
									<center>
										<figure>
										<div class="image"><img src="images/adalearn.png" alt="" width="450" height="250"/></div>
										<figcaption><a href="https://towardsdatascience.com/neural-network-optimization-7ca72d4db3e0">fig.</a> Adaptive learning rates.</figcaption>
										</figure>
									</center>

								
									<li><b>AdaGrad:</b> <br> 
										In SGD, a random term is added to the gradient to update the weights and speed up the path to optimization, 
										whereas here the parameters are updated to achieve the same goal. This updation factor is proportional to the importance of 
										the parameter, thus called adaptive.

										<p>
											One of the advantages of AdaGrad is that it eliminates the use of learning rate parameter. Thus achieves greater progress
											along gently sloped directions.
										</p>
									</li>
									<center>
										<figure>
										<div class="image"><img src="images/adagrad.png" alt="" width="450" height="150"/></div>
										<figcaption><a href="https://towardsdatascience.com/neural-network-optimization-7ca72d4db3e0">fig.</a> AdaGrad gradient updation.</figcaption>
										</figure>
									</center>
									
									&nbsp; 
									<center>
									<math>

									where,

									Θ<sub>i</sub> = i<sup>th</sup> parameter; <br> 
									r<sub>i</sub> = cumulative gradient of i<sup>th</sup> parameter; <br> 
									g<sub>i</sub> = current gradient of i<sup>th</sup> parameter; <br> 
									δ, ε ~ N(0,1) (iid) <br> 


									</math>
									</center>


									<li><b>RMSProp</b> <br> 
										AdaGrad does not do well for non-convex problems as it can prematurely decrease the speed of learning by giving equal weights to gradients at all 
										stages. In order to speed up the optimization, steep slopes must be given higher weights. That is exactly what RMSProp does.
									</li>
									<center>
									<figure>
									<div class="image"><img src="images/rmsprop.png" alt="" width="200" height="100"/></div>
									<figcaption><a href="https://towardsdatascience.com/neural-network-optimization-7ca72d4db3e0">fig.</a> RMSProp exponential gradient updation</figcaption>
									</figure>
								
									<math>

									where,
									ρ = [0,1] <br> 


									</math>
									</center>
					
								</ul>

								<h3>Conclusion:</h3>
								<p>Using Neural Networks for non-convex optimizations is still tricky. We need to make additional adjustments to conventional gradient descent 
								approach that is followed in the deep learning process to use them. If the adjusted models are accurate, they would take longer time to converge. 
								If approximations are made, it could lead to poor conditioning, which means slower learning rates, rapid changes in output for a small change in inputs etc., 
								as the optimization process is not stable. </p>
								
								<p>Genetic Algorithms on the other hand are specifically designed to solve 
									optimization problems and hence do not face most of the challenges faced by Neural Networks. 
									But as it is a heuristic approach, there are some approximations involved. Hence, solutions may not be very accurate.
									Now the question to ask when selecting an algorithm for our optimization problem is our threshold for accuracy and speed.
									Accordingly, we can map out the accuracy levels and time for converging for these algorithms and choose the most desired one.</p>
									
								<p>
									So I infer that though Genetic Algorithms are the go-to solutions to non-convex optimizations, we need to consider
									other factors like accuracy, ease of customization etc., to pick the desired algorithm.
								</p>
							</ol>

							</section>

							<button id="myBtn"><a href="#top" style="color: rgb(255, 255, 255)">Back to top</a></button>
							
					</div>

				
				<!-- Footer -->
				<footer id="footer">
					<section class="split contact">
						<section class="alt">
							<h3>Address</h3>
							<p>Boston, MA</p>
						</section>
						<section>
							<h3>Email</h3>
							<p><a href="adarshkuthuru@gmail.com">adarshkuthuru@gmail.com</a></p>
						</section>
						<section>
							<h3>Social</h3>
							<ul class="icons alt">
								<li><a href="https://www.linkedin.com/in/adarshkp1/" class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
								<li><a href="https://github.com/adarshkuthuru?tab=repositories" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							</ul>
						</section>
					</section>
				</footer>

				<!-- Copyright -->
				<div id="copyright">
					<ul><li>&copy; adarshkuthuru</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
				</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>